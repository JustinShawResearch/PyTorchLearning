{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFNSXmqGmCqXFWZlv2UrDD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustinShawResearch/PyTorchLearning/blob/main/00.PyTorch%20Fundamentals/00_PyTorch_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 00. PyTorch Fundamentals\n",
        "\n",
        "- [Learn the basics](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
        "- [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
        "- [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)"
      ],
      "metadata": {
        "id": "IX8FY2-3DCh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ0yhRkUDQPi",
        "outputId": "5f74ff66-702b-4427-9b93-3ae70fc6b098"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### Creating tensors\n",
        "\n",
        "PyTorch tensors are created using [`torch.Tensor()`](https://pytorch.org/docs/stable/tensors.html)"
      ],
      "metadata": {
        "id": "_bUVKAM9DZ-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfKO25xLDinC",
        "outputId": "32a30e1d-6a13-418f-d95e-7a1803503c2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZh2TuXXDtN0",
        "outputId": "45de6d53-3288-4c8c-9ed6-d21a915751ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])"
      ],
      "metadata": {
        "id": "BAmwkiX3Ef8e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcpTlBdEldG",
        "outputId": "b23ad5f1-9394-4e2f-dc72-2f0dc9601cd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKIR0hQuFsJR",
        "outputId": "41f4dfc1-b697-4b05-d80b-5494f0170908"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "matrix = torch.tensor([[7,8],\n",
        "                       [9,10]])\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_CzBJW9Ftoc",
        "outputId": "b606f8e1-e25c-4980-d3ea-cf443ce5a463"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLM3HluYF6z8",
        "outputId": "ae7e2d87-408b-4fec-cc97-9968ac0d9c46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QemXjgEdGBzD",
        "outputId": "92950b28-9bf6-4fac-ceb6-678cc4819f69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [7, 8, 9]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YQlxk3uGF8c",
        "outputId": "2200ef5f-1427-41ec-928c-62149d64c011"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkLA3xuzGVtY",
        "outputId": "2a10f95e-001a-4685-af94-e7d1a8cc0222"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wu6QitlGZkP",
        "outputId": "f85d1590-a9d7-40f8-cc2f-cc769ff83faf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random tensors\n",
        "\n",
        "Why random tensors?\n",
        "\n",
        "Random tensors are important because they way many NN learn is that they start with tensors full of random numbers and the adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update`\n",
        "\n",
        "Using [torch.Rand](https://pytorch.org/docs/stable/tensors.html)"
      ],
      "metadata": {
        "id": "j1zObMMGGdIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(1, 3, 3)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAr5yksC8-Bm",
        "outputId": "a7764848-f485-4490-9dcc-0f5ac5fac03c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.1435, 0.1931, 0.8456],\n",
              "         [0.5590, 0.8710, 0.4021],\n",
              "         [0.9380, 0.3575, 0.2976]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCXVPiqK9uEu",
        "outputId": "942ada1c-5759-4bbf-ac69-d2a41a9dfb19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and ones\n",
        "\n",
        "using [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
        "\n",
        "Again, the `size` parameter comes into play."
      ],
      "metadata": {
        "id": "hBZ3-1zKCWFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor full of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re_Hbvi-CaNu",
        "outputId": "cada0691-ecc8-4829-bfcb-ca95af41a584"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-n3bmJ7CfVt",
        "outputId": "aa26735e-dbd2-4dee-f35f-6d372378aaf5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range of tesnors and tensors like"
      ],
      "metadata": {
        "id": "9xZ9oVNJCvOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IqUs81d9W4W",
        "outputId": "b07461ea-6e3b-42c2-ab3c-a37bb86ce481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a404776195c1>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Use torch.arange(), torch.range() is deprecated\n",
        "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
        "\n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ],
      "metadata": {
        "id": "K4fvGcWWG9X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GgokIfyIGN0",
        "outputId": "fdeafe11-fced-48e4-bb17-d977ffc633fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "Data types are very important for precision in computing. It is one of the 3 big errors you will run into with PyTorch and deep learning\n",
        "\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device"
      ],
      "metadata": {
        "id": "OHmtKu7CIIDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y_TOlkMKIYJ",
        "outputId": "a5a34063-8993-43dd-ec04-c3d735c0cb3a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing datatype"
      ],
      "metadata": {
        "id": "PMgEgxsLKIs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDNuX86jLZTZ",
        "outputId": "ea9121b6-add8-4cb3-c06b-e34fc5248ff9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting information from tensors\n",
        "\n",
        "When creating/receiving tensors, it is good practice to get some information from them.\n",
        "\n",
        "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "* `dtype` - what datatype are the elements within the tensor stored in?\n",
        "* `device` - what device is the tensor stored on? (usually GPU or CPU)"
      ],
      "metadata": {
        "id": "Ej9Jxh0mLZgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12PW6Am4Pd6y",
        "outputId": "3e70f136-dd78-422c-844f-0c27834b361e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9262, 0.3638, 0.0919, 0.4187],\n",
            "        [0.3821, 0.2997, 0.4855, 0.0868],\n",
            "        [0.6040, 0.9120, 0.8223, 0.5072]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** When running into issues in PyTorch, it's very often one to do with one of the three attributes above"
      ],
      "metadata": {
        "id": "zQm2q_9xPhRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (tensor operations)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ],
      "metadata": {
        "id": "KIzu5mB6P0wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic operations"
      ],
      "metadata": {
        "id": "vY1HQwmeQtbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDncaiZDQ9Tt",
        "outputId": "a7774e2d-a5e2-4995-f25b-8a51af76c6e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjEGi8cDQ_o2",
        "outputId": "b2bd8774-cabc-4146-ce39-5d8ad590e205"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors don't change unless reassigned\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnUHiF7WRA42",
        "outputId": "ed0b5e16-85b1-4f89-9878-6d110fcc82cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ9j0DwURCMt",
        "outputId": "1a8de7d1-ff36-4746-f4f5-5780dc29b888"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfMQiTPqRErZ",
        "outputId": "00cdea1d-3daf-49ea-80ad-4d66b35e7a49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch also has a bunch of built-in functions like [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (short for multiplication) and [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) to perform basic operations."
      ],
      "metadata": {
        "id": "5V-IU5fZRE3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use torch functions\n",
        "torch.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FKH6Q-KRKxY",
        "outputId": "fd3a3a65-c9c7-441b-bbaf-5cdb8946b131"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use torch functions\n",
        "torch.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch9jPgGqRPZ2",
        "outputId": "3372782b-5043-4051-f83a-932d802aa1c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor is still unchanged\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztJAvBiwRPrT",
        "outputId": "50994f4f-e5d1-4ff1-87db-ee79002d20f6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, it's more common to use the operator symbols like * instead of torch.mul()"
      ],
      "metadata": {
        "id": "bvUvM7OnRaTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK8JwbfjRal8",
        "outputId": "6b47558d-2fed-4ef6-cffb-15da0bee955a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix multiplicaiton (is all you need, most common)\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "  * `(3, 2) @ (3, 2)` won't work\n",
        "  * `(2, 3) @ (3, 2)` will work\n",
        "  * `(3, 2) @ (2, 3)` will work\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "> **Resource:** see all of the rules for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html)."
      ],
      "metadata": {
        "id": "jxkVNG5XRiHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |"
      ],
      "metadata": {
        "id": "ixbd_OAISzGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3liEWAMS9wj",
        "outputId": "1a1b6ca6-f637-4a82-af98-de3c7d7b933d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL2m2mWkS_yM",
        "outputId": "b930de71-a532-430a-ad37-af97b1793e06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can do matrix multiplication by hand but it's not recommended.\n",
        "\n",
        "The in-built torch.matmul() method is **faster**.\n"
      ],
      "metadata": {
        "id": "GEmSVskjS_8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoKwcImQTDVw",
        "outputId": "b1561d62-9769-4275-ccb9-0d0c6b38b22a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.39 ms, sys: 80 µs, total: 1.47 ms\n",
            "Wall time: 9.82 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6-N5KzRTE6h",
        "outputId": "a5d27de6-be0e-4f5f-cbb3-7ba0935ace4c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 519 µs, sys: 687 µs, total: 1.21 ms\n",
            "Wall time: 2.77 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One of the most common errors in deep learning (shape errors)\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most **common errors  in deep learning is shape mismatches.**"
      ],
      "metadata": {
        "id": "QTMVWkF2TGUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "metadata": {
        "id": "KFbQyQ0TTYQS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "matrix multiplication will work between tensor_A and tensor_B by making their inner dimensions match.\n",
        "\n",
        "One of the ways to do this is with a transpose (switch the dimensions of a given tensor).\n",
        "\n",
        "performing transposes in PyTorch using either:\n",
        "\n",
        "torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
        "tensor.T - where tensor is the desired tensor to transpose."
      ],
      "metadata": {
        "id": "TG2_M9hcUJod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldqgM-piUWsX",
        "outputId": "80d4e48c-2629-4668-a189-bc1a4bb4c8a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yGZ_F1KUcGr",
        "outputId": "d661f8e5-59b1-4c82-842b-98a25f5fdd21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPqecjJjUcbL",
        "outputId": "53e1dba3-7fd9-44a2-e553-7db969b2dc6b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) which is a short for `torch.matmul()` also works\n"
      ],
      "metadata": {
        "id": "2m1qbS12UiBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgtfyyv7VKhg",
        "outputId": "f00fd40a-a8c8-402c-8505-86998845575b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the min, max, mean, sum, etc (aggregation)\n",
        "aggregation -> going from more values to less values"
      ],
      "metadata": {
        "id": "pUS5PhiwVLyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl3go8tmW7No",
        "outputId": "2a4c4207-6a4e-472c-f86f-38fb699b8b0d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performing aggregation\n",
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65a7n_fDW_Lc",
        "outputId": "ddfa1f55-126c-4acd-b139-5a4b149fb46e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positional min/max\n",
        "The index of a tensor where the max or minimum occurs with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful for finding the position where the highest (or lowest) value is and not the actual value itself (used in [softmax activation function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
      ],
      "metadata": {
        "id": "tLtW2_ACXBLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNu_GI2KXkW1",
        "outputId": "b21a1cbf-27a4-45be-86f9-2f934f6f30e8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change tensor datatype\n",
        "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.\n",
        "\n",
        "But there's a solution.\n",
        "\n",
        "changing the datatypes of tensors using torch.Tensor.type(dtype=None) where the dtype parameter is the datatype\n",
        "\n"
      ],
      "metadata": {
        "id": "7I4_qgHAXoro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "924cfmRGY3NW",
        "outputId": "8e8b6453-7f9f-4d1b-e781-b9502895b1d0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating another tensor the same as before but change its datatype to torch.float16."
      ],
      "metadata": {
        "id": "GubNBX8BY3ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "katphCqhY6iU",
        "outputId": "268bbafa-8045-422c-bd7d-edd4d45aae33"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts."
      ],
      "metadata": {
        "id": "_XmxUyDYZCaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "When wanting to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, errors will occur.\n"
      ],
      "metadata": {
        "id": "rKWcoOf-ZGOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "an example of `torch.reshape()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "gP1VxZKENBLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 11.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "id": "Jb42t1mrZZzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d3c924-fc6b-4d61-d8f5-3175ef81a3c2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(2, 5)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbudTI5DZjXN",
        "outputId": "c76eb0b6-f2ae-471b-c8b5-49cff9b1dc82"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
              "         [ 6.,  7.,  8.,  9., 10.]]),\n",
              " torch.Size([2, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " change the view with `torch.view()`."
      ],
      "metadata": {
        "id": "t0Vaz8AzNRbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 10)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zFEwvpPNa-i",
        "outputId": "b5c616c2-8733-4037-cb42-63b1245256d9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
              " torch.Size([1, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "changing the view of a tensor with `torch.view()` really only creates a new view of the same tensor.\n",
        "\n",
        "So changing the view changes the original tensor too"
      ],
      "metadata": {
        "id": "gDqv_D48N1sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_aXB8W_OBVn",
        "outputId": "e79ca131-d66d-4646-8d38-d3fbb23abb95"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
              " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ],
      "metadata": {
        "id": "cjoAI7P7OCo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked = torch.stack([x, x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s522icdxOIh3",
        "outputId": "d0f18ad8-0e8b-4ccf-d959-350c77108db6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
              "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
              "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
              "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
              "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked = torch.stack([x, x, x, x], dim=1) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpGw7qtlOLnH",
        "outputId": "2628e880-cb94-4ac9-d54f-05be672f9324"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  5.,  5.,  5.],\n",
              "        [ 2.,  2.,  2.,  2.],\n",
              "        [ 3.,  3.,  3.,  3.],\n",
              "        [ 4.,  4.,  4.,  4.],\n",
              "        [ 5.,  5.,  5.,  5.],\n",
              "        [ 6.,  6.,  6.,  6.],\n",
              "        [ 7.,  7.,  7.,  7.],\n",
              "        [ 8.,  8.,  8.,  8.],\n",
              "        [ 9.,  9.,  9.,  9.],\n",
              "        [10., 10., 10., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing all single dimensions from a tensor using `torch.squeeze()`"
      ],
      "metadata": {
        "id": "FgIgqdtsORDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {z}\")\n",
        "print(f\"Previous shape: {z.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "z_squeezed = z.squeeze()\n",
        "print(f\"\\nNew tensor: {z_squeezed}\")\n",
        "print(f\"New shape: {z_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw9wWA10OhGE",
        "outputId": "e1fcba80-9879-44a7-a3d2-9069efc8bc3b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
            "Previous shape: torch.Size([1, 10])\n",
            "\n",
            "New tensor: tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
            "New shape: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.unsqueeze()` is the opposite of `torch.squeeze` which is *adding* a dimension value of 1 at a specific index"
      ],
      "metadata": {
        "id": "Rsb_YP-SOj9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {z_squeezed}\")\n",
        "print(f\"Previous shape: {z_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "z_unsqueezed = z_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {z_unsqueezed}\")\n",
        "print(f\"New shape: {z_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73G_USrWPJyz",
        "outputId": "43803216-c64e-45d8-c217-23ce33ee512f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
            "Previous shape: torch.Size([10])\n",
            "\n",
            "New tensor: tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
            "New shape: torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rearrange the order of axes values with `torch.permute(input, dims)`, where the `input` gets turned into a *view* with new `dims`."
      ],
      "metadata": {
        "id": "O1CLtwjmPO_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3)) # [height, width, colour_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\") # [colour_channels, height, width]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGkGTU7ePdsy",
        "outputId": "367c2965-10ea-49cd-fcd2-3f4c810244dc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and changing the values in the view, it will change the values of the original."
      ],
      "metadata": {
        "id": "STcuju89PfJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "selecting specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ],
      "metadata": {
        "id": "T6ajQ0apPsbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awc2HkqBXOjK",
        "outputId": "fca792cc-2907-4a1b-d153-30616f8abe34"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ],
      "metadata": {
        "id": "US12h5fbXY2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4YskO2cXbPT",
        "outputId": "958a0410-ce37-4108-e7b2-d9f794b1ff16"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ],
      "metadata": {
        "id": "K09-yeqdXeqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJmNcp64Xk17",
        "outputId": "c3e19b91-44b6-441c-f728-4d639badb66c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPk4cfnnXqUy",
        "outputId": "64ec92d0-7f52-4948-c519-ad19014147b6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyj7I82nXsba",
        "outputId": "6b411bb1-1b55-41ca-edf3-06b5f7490118"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # same as x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbNYEg24XuJf",
        "outputId": "37bcc15f-f659-47be-809b-e38c675a175c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pythorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods:\n",
        "\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "OuOxWm_8XvrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzKsIq9DRknc",
        "outputId": "6074e700-f876-4503-b6f8-9d81efcebd13"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64`. Converting it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So converting a NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
        "\n",
        "Because we reassigned `tensor` above, by changing the tensor, the array stays the same."
      ],
      "metadata": {
        "id": "LoaNprQhRqzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the array, keep the tensor\n",
        "array = array + 1\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6LzxF9TSfUh",
        "outputId": "4427276e-a827-4bd9-e098-c722b04b1dd8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "go from PyTorch tensor to NumPy array, you can call tensor.numpy()."
      ],
      "metadata": {
        "id": "_mNKIaqiShGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsyc3sRlS3do",
        "outputId": "7491a77a-be65-4e6f-ac3f-b688491deabf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the same rule applies as above, changing the original tensor, the new numpy_tensor stays the same."
      ],
      "metadata": {
        "id": "TAK_aU5AS83N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the tensor, keep the array the same\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9xtCdlWS_9T",
        "outputId": "15d36485-b81b-4d37-e54c-c9a8bd8bbf62"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility (trying to take the random out of random)\n",
        "\n",
        "``start with random numbers -> tensor operations -> try to make better (again and again and again)``\n",
        "\n",
        "With less randomness, repeatable experiments can be performed\n",
        "\n",
        "On computer A, an algorithm was capable of achieving X performance. If computer B wants to reproduce the performance X, it can do so as seen below in the concept of a **random seed**\n",
        "\n",
        "pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this)"
      ],
      "metadata": {
        "id": "fEjmbjfnTBHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WNHsARLWPE4",
        "outputId": "1377c766-8a63-43eb-ffbf-e451ac1d34ad"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8658, 0.0472, 0.6265, 0.8634],\n",
            "        [0.2399, 0.7008, 0.0812, 0.4155],\n",
            "        [0.2372, 0.7337, 0.4149, 0.8135]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.0488, 0.0589, 0.2488, 0.3927],\n",
            "        [0.5835, 0.9311, 0.5044, 0.1630],\n",
            "        [0.7463, 0.6682, 0.5021, 0.3369]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tensors come out with different values.\n",
        "\n",
        "But how can two random created tensors be of the same values?\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer"
      ],
      "metadata": {
        "id": "qmusfgXYXX1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHWhrXjeX8--",
        "outputId": "9c3751a0-f4e2-4f77-e3bf-f37d59717d8b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More on randomness:\n",
        "> * [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed)"
      ],
      "metadata": {
        "id": "dyMPbzzMX9O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
        "\n",
        "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n",
        "\n",
        "[Nvidia GPU with CUDA](https://developer.nvidia.com/cuda-gpus)\n",
        "(CUDA is a computing platform and API that helps allow GPUs be used for general purpose computing & not just graphics) unless otherwise specified."
      ],
      "metadata": {
        "id": "N2pPAyukYWNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Getting a GPU\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |"
      ],
      "metadata": {
        "id": "R07nj-47dcrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking access to a Nvidia GPU, you can run `!nvidia-smi` where the\n",
        "\n",
        "> Note:\n",
        "`!` (also called bang) means \"run this on the command line\"."
      ],
      "metadata": {
        "id": "UE4ZLdFudcGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyEFCOHhiFBx",
        "outputId": "3572de58-c8fe-4db3-b52f-f78cd396384b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 24 17:20:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Getting PyTorch to run on the GPU\n",
        "\n",
        "When GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
        "\n",
        "To do so, use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n",
        "\n",
        "> Note: it is [good practice](https://pytorch.org/docs/stable/notes/cuda.html#best-practices) to use device agnostic code."
      ],
      "metadata": {
        "id": "k8qCb2niiG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxJ33tLCimM-",
        "outputId": "a37eb151-8d4f-47b9-d43c-83e975a77b87"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ex7yGGrMjF_N",
        "outputId": "a2f8dc88-c9fa-4ffd-ca7c-63b383ff1063"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do faster computing you can use a GPU but if you want to do *much* faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ],
      "metadata": {
        "id": "QA6VyCQXjiu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwotqYNBjtF5",
        "outputId": "2bca2edc-6d35-41f7-f587-68ad49b1bdb0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "putting tensors on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n"
      ],
      "metadata": {
        "id": "2gvsULTAj-W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnb-ElMat41a",
        "outputId": "1cd0ef32-87c9-431b-f7ab-513df4b204b1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Moving tensors back to the CPU\n",
        "\n",
        "We may want to move tensors back to the CPU to interact tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Using [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu` will give an error"
      ],
      "metadata": {
        "id": "HgTmPVSBt7zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "try:\n",
        "    # Trying to convert a GPU tensor directly to a NumPy array will raise an error\n",
        "    numpy_array = tensor_on_gpu.numpy()\n",
        "except TypeError as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SqRXPBswLvO",
        "outputId": "662cf014-270d-4ac9-fb04-d79212356460"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy, use [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
        "\n",
        "This copies the tensor to CPU memory so it's usable with CPUs."
      ],
      "metadata": {
        "id": "HSIsGYcmwbmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GkFmXW5wjGC",
        "outputId": "6758f7a4-6b7e-43ad-f233-b188b4cb16fb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MpAVYBswmzp",
        "outputId": "15df18c7-3722-46d8-9674-14754ee77527"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it for the fundamentals. I could not really find anything else.\n",
        "\n",
        "Here are good reading for the basics at well!\n",
        "\n",
        "- [Learn the basics](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
        "- [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
        "- [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)"
      ],
      "metadata": {
        "id": "uY0SBFBSwqLJ"
      }
    }
  ]
}